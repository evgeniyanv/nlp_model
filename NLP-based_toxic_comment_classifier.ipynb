{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп» с BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "**Задача:**\n",
    "\n",
    "Обучить модель классифицировать комментарии на позитивные и негативные. То есть задача определения тональности текста.\n",
    "\n",
    "**Цель:**\n",
    "\n",
    "Модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Ход выполнения проекта**\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение моделей. \n",
    "3. Выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Файл `toxic_comments.csv`. \n",
    "\n",
    "`text` - текст комментария\n",
    "\n",
    "`toxic` — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Импорт библиотек<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Импорт основных библиотек\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "except:\n",
    "    !pip install spacy -q\n",
    "    import spacy\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModel\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "# константы\n",
    "\n",
    "RANDOM_STATE=42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим данные из csv-файла\n",
    "\n",
    "try: \n",
    "    df = pd.read_csv('toxic_comments.csv') \n",
    "except: \n",
    "    df = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обзор датасета\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# информация о датасете\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# пропуски\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# дубликаты\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# проверим баланс классов целевого признака\n",
    "\n",
    "class_distribution = df['toxic'].value_counts(normalize=True) * 100\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Построение диаграммы\n",
    "ax = class_distribution.plot(kind='bar', color=['lightblue', 'lightcoral'])\n",
    "\n",
    "# Настройки графика\n",
    "plt.xlabel('Класс')\n",
    "plt.ylabel('Доля, %')\n",
    "plt.title('Относительное распределение классов')\n",
    "plt.xticks(ticks=[0, 1], labels=['Класс 0', 'Класс 1'], rotation=0)\n",
    "plt.ylim(0, 100)  \n",
    "\n",
    "# Отображаем процентные значения над столбцами\n",
    "for i, v in enumerate(class_distribution):\n",
    "    ax.text(i, v + 1, f\"{v:.1f}%\", ha='center', fontsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидный дисбаланс. Класс 1 составляет всего 10% от всей выборки, поэтому этот класс модель может распознавать в итоге хуже. \n",
    "      \n",
    "Во-первых, будем использовать стратификацию при разделении на тренировочные и валидационные выборки. \n",
    "    \n",
    "Во-вторых, в моделях можно указывать параметр class_weight='balanced', указывая на несбалансированность классов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Очистка и лемматизация<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для очистки текста\n",
    "\n",
    "def clear_text(text):\n",
    "    t = re.sub(r'[^a-zA-z]', ' ', text)\n",
    "    t = t.split()\n",
    "    t = ' '.join(t)\n",
    "    return t\n",
    "\n",
    "df['сlear_text'] = df['text'].apply(clear_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель загружена!\n"
     ]
    }
   ],
   "source": [
    "# библиотека SpaCy\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\", \"textcat\"]) #исключим ненужные модули для ускорения\n",
    "except OSError:\n",
    "    print(\"Модель не найдена. Загружаем...\")\n",
    "    subprocess.run([\"python\", \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "print(\"Модель загружена!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лемматизация: 100%|█████████████████████| 30000/30000 [00:10<00:00, 2835.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      text     lemmatized_text\n",
      "0     The cats are running      the cat be run\n",
      "1  Children played outside  child play outside\n",
      "2        He watches movies      he watch movie\n",
      "3     The cats are running      the cat be run\n",
      "4  Children played outside  child play outside\n"
     ]
    }
   ],
   "source": [
    "# функция для лемматизации текста с прогрессом\n",
    "\n",
    "df_1 = pd.DataFrame({'text': [\"The cats are running\", \"Children played outside\", \"He watches movies\"] * 10000})  # 30K строк\n",
    "\n",
    "\n",
    "def lemmatize_with_progress(texts, data):\n",
    "    texts = map(str, texts) \n",
    "    docs = list(tqdm(nlp.pipe(texts), total=data.shape[0], desc=\"Лемматизация\"))\n",
    "    return [\" \".join([token.lemma_ for token in doc]) for doc in docs]\n",
    "\n",
    "# Применяем лемматизацию с прогрессом\n",
    "df_1['lemmatized_text'] = lemmatize_with_progress(df_1['text'], df_1)\n",
    "\n",
    "# Вывод первых строк\n",
    "print(df_1.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция работает корректно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Лемматизация: 100%|████████████████████| 159292/159292 [12:25<00:00, 213.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>сlear_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "      <td>d aww he match this background colour I m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "      <td>hey man I m really not try to edit war it s ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "      <td>More I can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          сlear_text  \\\n",
       "0  Explanation Why the edits made under my userna...   \n",
       "1  D aww He matches this background colour I m se...   \n",
       "2  Hey man I m really not trying to edit war It s...   \n",
       "3  More I can t make any real suggestions on impr...   \n",
       "4  You sir are my hero Any chance you remember wh...   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d aww he match this background colour I m seem...  \n",
       "2  hey man I m really not try to edit war it s ju...  \n",
       "3  More I can t make any real suggestion on impro...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выполним лемматизацию текста и добавим новый столбец в наш датасет\n",
    "df['lemm_text'] = lemmatize_with_progress(df['сlear_text'], df)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВЫВОД ПО РАЗДЕЛУ \"ПОДГОТОВКА\":**\n",
    "\n",
    "Данные состоят из одного датасета, в котором 3 столбца, в одном из них текст комментариев, в другом метка тональности текста (целевой признак)\n",
    "\n",
    "Пропусков и дубликатов в датасете не выявлено.\n",
    "\n",
    "Выявлен дисбаланс классов, минорный класс \"1\" составляет всего 10% от общего числа.\n",
    "\n",
    "Данные очищены с помощью созданной функции `clear_text` с использованием регулярных выражений `re`.\n",
    "Текст лемматизирован с помощью библиотеки SpaCy, для ускорения работы исключены модули `parser`, `ner`, `textcat`.\n",
    "\n",
    "Теперь данные готовы к формированию признаков для модели: разделению на выборки, векторизации и обучению моделей, которое будем осуществлять посредством пайплайна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Подготовка признаков<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127433,), (31859,), (127433,), (31859,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разделим данные на выборки: тренировочную и тестовую, добавим стратификацию\n",
    "\n",
    "X = df['lemm_text']\n",
    "y = df['toxic']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем признаки в векторы с помощью величин TF-IDF. Сделаем это в пайплайне.\n",
    "\n",
    "TF-IDF оценивает важность слова. TF отвечает за количество упоминаний слова в отдельном тексте, а IDF отражает частоту его употребления во всём корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/evgeniazigaeva/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Загрузим список стоп-слов, создадим список английских стоп-слов\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk_stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Логистическая регрессия<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим пайплайн для обработки текста с помощью TfidfVectorizer(), исключив стопслова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(stop_words=stopwords)),\n",
    "        ('models', LogisticRegression(solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Лучшие параметры: {'models__penalty': 'l2', 'models__C': 10}\n",
      "Лучший score: 0.76\n",
      "Время обучения: 3.55 сек\n",
      "Время предсказания: 1.26 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "param_lr = [\n",
    "    {\n",
    "        'models__C': [1, 10, 100],\n",
    "        'models__penalty': ['l1', 'l2']\n",
    "    }\n",
    "]\n",
    "\n",
    "random_lr = RandomizedSearchCV(\n",
    "    pipe_lr, \n",
    "    param_lr, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_lr.fit(X_train, y_train)\n",
    "\n",
    "# создадим функцию выдачи результатов\n",
    "def results(model):\n",
    "    results = model.cv_results_\n",
    "    best_index = model.best_index_\n",
    "    best_score = model.best_score_\n",
    "    params = results['params'][best_index]\n",
    "    fit_time = results['mean_fit_time'][best_index]\n",
    "    predict_time = results['mean_score_time'][best_index]\n",
    "    return params, best_score, fit_time, predict_time  \n",
    "\n",
    "params_lr, best_score_lr, fit_time_lr, predict_time_lr = results(random_lr)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_lr}\")\n",
    "print(f\"Лучший score: {best_score_lr:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_lr:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_lr:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры Логистической регрессии l2-регуляризация с силой регуляризации 10.\n",
    "\n",
    "Метрика F1 равна 0.76, что удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Multinomial Naive Bayes (MultinomialNB)<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_nb = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(stop_words=stopwords)),\n",
    "        ('models', MultinomialNB())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Лучшие параметры: {'models__alpha': 0.1}\n",
      "Лучший score: 0.63\n",
      "Время обучения: 2.15 сек\n",
      "Время предсказания: 1.21 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "param_nb = [\n",
    "    {\n",
    "        'models__alpha': [0.1, 0.5, 1, 5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "random_nb = RandomizedSearchCV(\n",
    "    pipe_nb, \n",
    "    param_nb, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_nb.fit(X_train, y_train)\n",
    "\n",
    "params_nb, best_score_nb, fit_time_nb, predict_time_nb = results(random_nb)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_nb}\")\n",
    "print(f\"Лучший score: {best_score_nb:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_nb:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_nb:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшие параметры модели Наивный Байес alpha=0.1.\n",
    "\n",
    "Метрика F1 равна 0.63, что не удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> RandomForestClassifier (Случайный лес)<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(stop_words=stopwords)),\n",
    "        ('models', RandomForestClassifier(random_state=RANDOM_STATE))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Лучшие параметры: {'models__n_estimators': 50, 'models__min_samples_split': 5, 'models__min_samples_leaf': 5, 'models__max_depth': None}\n",
      "Лучший score: 0.52\n",
      "Время обучения: 8.14 сек\n",
      "Время предсказания: 1.95 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "param_rf = {\n",
    "    'models__n_estimators': [50, 100], \n",
    "    'models__max_depth': [None, 10, 20], \n",
    "    'models__min_samples_split': [2, 5, 10], \n",
    "    'models__min_samples_leaf': [2, 5], \n",
    "}\n",
    "\n",
    "random_rf = RandomizedSearchCV(\n",
    "    pipe_rf, \n",
    "    param_rf, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=-1\n",
    ")\n",
    "random_rf.fit(X_train, y_train)\n",
    "\n",
    "params_rf, best_score_rf, fit_time_rf, predict_time_rf = results(random_rf)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_rf}\")\n",
    "print(f\"Лучший score: {best_score_rf:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_rf:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_rf:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта модель отработала еще хуже. Лучшие параметры модели Случайный лес Количество деревьев=50, Глубина деревьев не ограничена, Минимальное количество выборок для разбиения=5, Минимальное количество выборок в листе=5\n",
    "\n",
    "Метрика F1 равна 0.52, что не удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Бустинговая модель LGBMClassifier<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_gbm = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(stop_words=stopwords)),\n",
    "        ('models', lgb.LGBMClassifier( \n",
    "    max_depth=5,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    random_state=RANDOM_STATE,\n",
    "    force_col_wise=True,\n",
    "    verbose=-1\n",
    "))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Лучшие параметры: {'models__num_leaves': 30, 'models__n_estimators': 300, 'models__max_depth': -1}\n",
      "Лучший score: 0.77\n",
      "Время обучения: 10.75 сек\n",
      "Время предсказания: 1.73 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "param_gbm = {\n",
    "    'models__n_estimators': [100, 200, 300],\n",
    "    'models__max_depth': [-1, 5],\n",
    "    'models__num_leaves': [10, 20, 30]\n",
    "}\n",
    "\n",
    "random_gbm = RandomizedSearchCV(\n",
    "    pipe_gbm, \n",
    "    param_gbm, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=1,\n",
    "    n_iter=3\n",
    ")\n",
    "\n",
    "random_gbm.fit(X_train, y_train)\n",
    "\n",
    "params_gbm, best_score_gbm, fit_time_gbm, predict_time_gbm = results(random_gbm)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_gbm}\")\n",
    "print(f\"Лучший score: {best_score_gbm:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_gbm:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_gbm:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдены лучшие параметры модели LGBM.\n",
    "Метрика F1 равна 0.77, что удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> BERT \"unitary/toxic-bert\"<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - модель для обработки текста, которую можно использовать для создания эмбеддингов (векторных признаков) и последующей классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобученный AutoTokenizer()\n",
    "\n",
    "model_name = \"unitary/toxic-bert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переводим модель в режим предсказания (выключаем градиенты)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания эмбеддингов\n",
    "\n",
    "def get_bert_embedding(text):\n",
    "    # Токенизация текста (обрезаем до 128 токенов)\n",
    "    tokens = tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "    # Передаём текст в BERT и отключаем градиенты (ускоряет работу)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "\n",
    "    # Используем эмбеддинг [CLS] токена (размерность 768)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввиду того, что датасет у нас достаточно массивный, а обработка bert ресурсоемка, выберем из датасета только 10000 случайных текстов с длиной сообщения не более 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72865</th>\n",
       "      <td>\"The artcile assert notability - \"\"famous\"\" - ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145991</th>\n",
       "      <td>GO AND FUCK WIKIPEDIA...WHO THE HELL CARES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66188</th>\n",
       "      <td>I hate you. U are a homosapian. Breasts</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97345</th>\n",
       "      <td>\"\\n\\n Capitalization \\n\\nThe capitalization of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122145</th>\n",
       "      <td>(I think kororima (which I thought might be ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27766</th>\n",
       "      <td>Bing Bang (Time to Dance)\\nWhat do you feel ne...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70000</th>\n",
       "      <td>You love the devil and worship him.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80391</th>\n",
       "      <td>Purpose phrases ==\\n A linguistic source about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105575</th>\n",
       "      <td>So my band's not notable? Try telling that all...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74533</th>\n",
       "      <td>i hope we can rectify this soon that we may go...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "72865   \"The artcile assert notability - \"\"famous\"\" - ...      0\n",
       "145991      GO AND FUCK WIKIPEDIA...WHO THE HELL CARES...      1\n",
       "66188             I hate you. U are a homosapian. Breasts      1\n",
       "97345   \"\\n\\n Capitalization \\n\\nThe capitalization of...      0\n",
       "122145  (I think kororima (which I thought might be ca...      0\n",
       "...                                                   ...    ...\n",
       "27766   Bing Bang (Time to Dance)\\nWhat do you feel ne...      0\n",
       "70000                 You love the devil and worship him.      1\n",
       "80391   Purpose phrases ==\\n A linguistic source about...      0\n",
       "105575  So my band's not notable? Try telling that all...      0\n",
       "74533   i hope we can rectify this soon that we may go...      0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# возьмем семпл\n",
    "\n",
    "df['len'] = df['text'].str.len()\n",
    "df_bert = df[df['len']<200]\n",
    "df_bert = df_bert.sample(n=10000, random_state=RANDOM_STATE)\n",
    "df_bert = df_bert[['text', 'toxic']]\n",
    "df_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0    86.33\n",
       "1    13.67\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# проверим соотношение классов в целевой переменной\n",
    "\n",
    "class_distribution = df_bert['toxic'].value_counts(normalize=True) * 100\n",
    "class_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END ....................models__C=1, models__penalty=l2; total time=   4.2s\n",
      "[CV] END ..................models__C=100, models__penalty=l1; total time=   7.0s\n",
      "[CV] END ..................................models__alpha=0.1; total time=   3.4s\n",
      "[CV] END ...................................models__alpha=10; total time=   3.0s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=100; total time=   5.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=50; total time=   4.7s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=50; total time=   4.4s\n",
      "[CV] END ....................models__C=1, models__penalty=l1; total time=   4.1s\n",
      "[CV] END ...................models__C=10, models__penalty=l2; total time=   4.6s\n",
      "[CV] END ....................................models__alpha=1; total time=   3.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=10, models__n_estimators=100; total time=   6.2s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=50; total time=   4.4s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=50; total time=   4.5s\n",
      "[CV] END ...................models__C=10, models__penalty=l1; total time=  11.4s\n",
      "[CV] END ..................................models__alpha=0.5; total time=   3.4s\n",
      "[CV] END ...................................models__alpha=10; total time=   2.9s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=2, models__min_samples_split=5, models__n_estimators=50; total time=   5.1s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=50; total time=   4.9s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=50; total time=   4.6s\n",
      "[CV] END ....................models__C=1, models__penalty=l1; total time=   4.0s\n",
      "[CV] END ...................models__C=10, models__penalty=l2; total time=   4.7s\n",
      "[CV] END ..................................models__alpha=0.5; total time=   3.4s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=100; total time=   5.5s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=50; total time=   4.4s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=100; total time=   5.2s\n",
      "[CV] END ....................models__C=1, models__penalty=l1; total time=   4.2s\n",
      "[CV] END ..................models__C=100, models__penalty=l1; total time=   6.8s\n",
      "[CV] END ....................................models__alpha=1; total time=   3.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=10, models__n_estimators=100; total time=   6.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=100; total time=   6.5s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=100; total time=   5.1s\n",
      "[CV] END ...................models__C=10, models__penalty=l1; total time=   5.5s\n",
      "[CV] END ..................models__C=100, models__penalty=l2; total time=   5.5s\n",
      "[CV] END ....................................models__alpha=5; total time=   3.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=2, models__min_samples_split=5, models__n_estimators=50; total time=   5.1s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=100; total time=   6.4s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=100; total time=   5.0s\n",
      "[CV] END ...................models__C=10, models__penalty=l2; total time=   5.1s\n",
      "[CV] END ..................models__C=100, models__penalty=l2; total time=   5.4s\n",
      "[CV] END ..................................models__alpha=0.1; total time=   3.3s\n",
      "[CV] END ....................................models__alpha=5; total time=   3.0s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=2, models__n_estimators=100; total time=   5.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=100; total time=   6.4s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=100; total time=   5.1s\n",
      "[CV] END ....................models__C=1, models__penalty=l2; total time=   4.3s\n",
      "[CV] END ..................models__C=100, models__penalty=l2; total time=   5.5s\n",
      "[CV] END ....................................models__alpha=1; total time=   3.4s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=10, models__n_estimators=100; total time=   6.3s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=2, models__min_samples_split=10, models__n_estimators=50; total time=   4.4s\n",
      "[CV] END models__max_depth=None, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=50; total time=   9.7s\n",
      "[CV] END ...................models__C=10, models__penalty=l1; total time=   5.8s\n",
      "[CV] END ..................................models__alpha=0.1; total time=   3.3s\n",
      "[CV] END ....................................models__alpha=5; total time=   3.0s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=2, models__min_samples_split=5, models__n_estimators=50; total time=   5.1s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=100; total time=   5.5s\n",
      "[CV] END models__max_depth=None, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=50; total time=  10.4s\n",
      "[CV] END ....................models__C=1, models__penalty=l2; total time=   4.2s\n",
      "[CV] END ..................models__C=100, models__penalty=l1; total time=   7.0s\n",
      "[CV] END ..................................models__alpha=0.5; total time=   3.4s\n",
      "[CV] END ...................................models__alpha=10; total time=   2.9s\n",
      "[CV] END models__max_depth=20, models__min_samples_leaf=5, models__min_samples_split=2, models__n_estimators=50; total time=   5.0s\n",
      "[CV] END models__max_depth=10, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=100; total time=   5.3s\n",
      "[CV] END models__max_depth=None, models__min_samples_leaf=5, models__min_samples_split=5, models__n_estimators=50; total time=  10.2s\n",
      "Размер X: (10000, 768)\n",
      "Размер y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем тексты в эмбеддинги\n",
    "\n",
    "X = np.array([get_bert_embedding(text) for text in df_bert['text']])\n",
    "y = df_bert['toxic'].values  # Метки\n",
    "\n",
    "# Убираем лишнее измерение\n",
    "X = X.squeeze()\n",
    "\n",
    "print(\"Размер X:\", X.shape)  \n",
    "print(\"Размер y:\", y.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные на train/test\n",
    "\n",
    "X_train_bert, X_test_bert, y_train_bert, y_test_bert = train_test_split(X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_bert = Pipeline(\n",
    "    [\n",
    "        ('models', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   2.6s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   2.2s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   2.3s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   5.2s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   4.4s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   4.8s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   2.0s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   2.0s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   2.0s\n",
      "Лучшие параметры: {'models__n_estimators': 100, 'models__max_depth': None, 'models': RandomForestClassifier(random_state=42)}\n",
      "Лучший score: 0.97\n",
      "Время обучения: 4.77 сек\n",
      "Время предсказания: 0.02 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "params = [\n",
    "    # словарь для модели RandomForestClassifier()\n",
    "    {\n",
    "        'models': [RandomForestClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__n_estimators': [50, 100],\n",
    "        'models__max_depth': [None, 10]\n",
    "\n",
    "    },\n",
    "    \n",
    "    # словарь для модели LGBM()\n",
    "    {\n",
    "        'models': [lgb.LGBMClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__n_estimators': [100, 200, 300],\n",
    "        'models__max_depth': [-1, 5]\n",
    "    },\n",
    "    \n",
    "     # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE)],\n",
    "        'models__C': [1, 10, 100],\n",
    "        'models__penalty': ['l1', 'l2'],\n",
    "        'models__solver': ['liblinear']\n",
    "    }\n",
    "]\n",
    "\n",
    "random_bert = RandomizedSearchCV(\n",
    "    pipe_bert, \n",
    "    params, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=1,\n",
    "    n_iter=3\n",
    ")\n",
    "\n",
    "random_bert.fit(X_train_bert, y_train_bert)\n",
    "\n",
    "params_bert, best_score_bert, fit_time_bert, predict_time_bert = results(random_bert)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_bert}\")\n",
    "print(f\"Лучший score: {best_score_bert:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_bert:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_bert:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика после обработка текста с библиотекой unitary/toxic-bert впечатляет.\n",
    "Метрика F1 равна 0.97, что удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> BERT базовая<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT - попробуем базовую библиотеку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем предобученный BERT\n",
    "\n",
    "model_base = \"bert-base-uncased\"\n",
    "tokenizer_base = BertTokenizer.from_pretrained(model_base)\n",
    "model_base = BertModel.from_pretrained(model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Переводим модель в режим предсказания (выключаем градиенты)\n",
    "\n",
    "model_base.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для создания эмбеддингов\n",
    "\n",
    "def get_bert_base_embedding(text):\n",
    "    # Токенизация текста (обрезаем до 128 токенов)\n",
    "    tokens = tokenizer_base(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "\n",
    "    # Передаём текст в BERT и отключаем градиенты (ускоряет работу)\n",
    "    with torch.no_grad():\n",
    "        output = model_base(**tokens)\n",
    "\n",
    "    # Используем эмбеддинг [CLS] токена (размерность 768)\n",
    "    return output.last_hidden_state[:, 0, :].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ввиду того, что датасет у нас достаточно массивный, а обработка bert ресурсоемка, выберем из датасета только 10000 случайных текстов с длиной сообщения не более 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер X: (10000, 768)\n",
      "Размер y: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Преобразуем тексты в эмбеддинги\n",
    "\n",
    "X_base = np.array([get_bert_base_embedding(text) for text in df_bert['text']])\n",
    "y_base = df_bert['toxic'].values  # Метки\n",
    "\n",
    "# Убираем лишнее измерение\n",
    "X_base = X_base.squeeze()\n",
    "\n",
    "print(\"Размер X:\", X_base.shape)  \n",
    "print(\"Размер y:\", y_base.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделяем данные на train/test\n",
    "\n",
    "X_train_base, X_test_base, y_train_base, y_test_base = train_test_split(X_base, y_base, test_size=0.2, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_base = Pipeline(\n",
    "    [\n",
    "        ('models', LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   4.0s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   3.9s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=50; total time=   4.2s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   8.0s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   7.9s\n",
      "[CV] END models=RandomForestClassifier(random_state=42), models__max_depth=None, models__n_estimators=100; total time=   8.0s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   3.4s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   3.4s\n",
      "[CV] END models=LGBMClassifier(random_state=42), models__max_depth=-1, models__n_estimators=200; total time=   3.4s\n",
      "Лучшие параметры: {'models__n_estimators': 200, 'models__max_depth': -1, 'models': LGBMClassifier(n_estimators=200, random_state=42)}\n",
      "Лучший score: 0.66\n",
      "Время обучения: 3.42 сек\n",
      "Время предсказания: 0.01 сек\n"
     ]
    }
   ],
   "source": [
    "# Соберем словарь из перебираемых гиперпараметров\n",
    "\n",
    "params = [\n",
    "    # словарь для модели RandomForestClassifier()\n",
    "    {\n",
    "        'models': [RandomForestClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__n_estimators': [50, 100],\n",
    "        'models__max_depth': [None, 10]\n",
    "\n",
    "    },\n",
    "    \n",
    "    # словарь для модели LGBM()\n",
    "    {\n",
    "        'models': [lgb.LGBMClassifier(random_state=RANDOM_STATE)],\n",
    "        'models__n_estimators': [100, 200, 300],\n",
    "        'models__max_depth': [-1, 5]\n",
    "    },\n",
    "    \n",
    "     # словарь для модели LogisticRegression()\n",
    "    {\n",
    "        'models': [LogisticRegression(solver='liblinear', class_weight='balanced', random_state=RANDOM_STATE)],\n",
    "        'models__C': [1, 10, 100],\n",
    "        'models__penalty': ['l1', 'l2'],\n",
    "        'models__solver': ['liblinear']\n",
    "    }\n",
    "]\n",
    "\n",
    "random_base = RandomizedSearchCV(\n",
    "    pipe_base, \n",
    "    params, \n",
    "    cv=3,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    error_score='raise',\n",
    "    n_jobs=1,\n",
    "    n_iter=3\n",
    ")\n",
    "\n",
    "random_base.fit(X_train_base, y_train_base)\n",
    "\n",
    "params_base, best_score_base, fit_time_base, predict_time_base = results(random_base)\n",
    "\n",
    "print(f\"Лучшие параметры: {params_base}\")\n",
    "print(f\"Лучший score: {best_score_base:.2f}\")\n",
    "\n",
    "# затраченное время\n",
    "print(f\"Время обучения: {fit_time_base:.2f} сек\")\n",
    "print(f\"Время предсказания: {predict_time_base:.2f} сек\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрика после обработка текста с базовой библиотекой BERT неудовлетворительна.\n",
    "Метрика F1 равна 0.66, что не удовлетворяет заданию (>0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Итоги<a class=\"tocSkip\"> </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BERT+RandomForest</th>\n",
       "      <td>4.767160</td>\n",
       "      <td>0.015086</td>\n",
       "      <td>0.965248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>10.754857</td>\n",
       "      <td>1.733990</td>\n",
       "      <td>0.774333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>3.549488</td>\n",
       "      <td>1.259758</td>\n",
       "      <td>0.761848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BERT_base+LGBM</th>\n",
       "      <td>3.417952</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.659410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>2.145118</td>\n",
       "      <td>1.212143</td>\n",
       "      <td>0.627882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForest</th>\n",
       "      <td>8.144620</td>\n",
       "      <td>1.949615</td>\n",
       "      <td>0.521674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fit_time  predict_time        f1\n",
       "Model                                                \n",
       "BERT+RandomForest    4.767160      0.015086  0.965248\n",
       "LightGBM            10.754857      1.733990  0.774333\n",
       "LogisticRegression   3.549488      1.259758  0.761848\n",
       "BERT_base+LGBM       3.417952      0.007821  0.659410\n",
       "MultinomialNB        2.145118      1.212143  0.627882\n",
       "RandomForest         8.144620      1.949615  0.521674"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# сравнение метрик моделей\n",
    "\n",
    "data = {\n",
    "    'Model': ['LogisticRegression', 'MultinomialNB', 'RandomForest', 'LightGBM', 'BERT+RandomForest', 'BERT_base+LGBM'],\n",
    "    'fit_time': [fit_time_lr, fit_time_nb, fit_time_rf, fit_time_gbm, fit_time_bert, fit_time_base],\n",
    "    'predict_time': [predict_time_lr, predict_time_nb, predict_time_rf, predict_time_gbm, predict_time_bert, predict_time_base],\n",
    "    'f1': [best_score_lr, best_score_nb, best_score_rf, best_score_gbm, best_score_bert, best_score_base]\n",
    "}\n",
    "\n",
    "# Создаём DataFrame\n",
    "df_results = pd.DataFrame(data)\n",
    "df_results.set_index('Model', inplace=True)\n",
    "df_results.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT с библиотекой unitary/toxic-bert показала лучший результат.\n",
    "Проверим метрику на тесте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика f1 на тестовой выборке: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Оцениваем на тестовых данных\n",
    "\n",
    "y_test_pred = random_bert.predict(X_test_bert)\n",
    "\n",
    "print(f'Метрика f1 на тестовой выборке: {f1_score(y_test_bert, y_test_pred):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поставлена задача построения модели для прогноза тональности текста.\n",
    "\n",
    "*Ход работы:*\n",
    "\n",
    "1. Загрузка данных и подготовка.\n",
    "\n",
    "В данных пропусков и дубликатов не обнаружено. \n",
    "Обнаружен дисбаланс классов. Класс 1 составляет всего 10% от всей выборки, поэтому этот класс модель может распознавать в итоге хуже.\n",
    "Решено использовать стратификацию при разделении на тренировочные и валидационные выборки.\n",
    "\n",
    "Подготовка данных осуществлена двумя методами:\n",
    "- с лемматизацией с помощью библиотеки SpaCy\n",
    "- с моделью BERT, использующую создание эмбендингов\n",
    "\n",
    "2. Обучение моделей с лемматизированными признаками.\n",
    "\n",
    "Для обучения моделей текст был очищен от лишних символов и лемматизирован, т.е. все слова приведены к их начальной форме.\n",
    "\n",
    "Данные были разделены на выборки тренировочную и тестовую (20%)\n",
    "Создан пайплайн с предварительной трансформацией признаков в векторы с помощью величин TF-IDF.\n",
    "\n",
    "Обучено 4 модели и получены метрики `f1` с лучшими гиперпараметрами на кросс-валидации: \n",
    "\n",
    "- Логистическая регрессия - 0.77\n",
    "- Наивный Байес - 0.63\n",
    "- Случайный лес  - 0.53\n",
    "- модель градиентного бустинга LightGBM - 0.77\n",
    "\n",
    "3. Обучение моделей с BERT.\n",
    "\n",
    "Для трансформации текста в эмбендинги были опробованы две библиотеки BERT `unitary/toxic-bert` и `bert-base-uncased`, мы только предсказываем на уже предобученных моделях. \n",
    "\n",
    "Ввиду того, что датасет у нас достаточно массивный, а обработка bert ресурсоемка, решено взять семпл на 10000 текстов с длиной сообщения не более 300.\n",
    "\n",
    "Готовые эмбендинги разделены на выборки тренировочную (80%) и тестовую (20%).\n",
    "С помощью `RandomizedSearchCV` осуществлен подбор лучшей модели с лучшими параметрами среди:\n",
    "- Логистическая регрессия\n",
    "- Случайный лес\n",
    "- модель градиентного бустинга LightGBM\n",
    "\n",
    "Результат лучшей метрики с библиотекой `unitary/toxic-bert` оказался отличным 0.97, когда как базовая библиотека дала метрику `f1` 0.66.\n",
    "\n",
    "4. Проверка данных на тестовой выборке.\n",
    "\n",
    "Лучшей метрикой на кросс-валидации обладает модель BERT с использованием библиотеки `unitary/toxic-bert`. \n",
    "\n",
    "При тестировании этой модели на тестовых данных получена метрика `f1` равная 0.96, удовлетворяющая порогу задания >0.75.\n"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2602,
    "start_time": "2025-03-12T08:19:10.176Z"
   },
   {
    "duration": 2694,
    "start_time": "2025-03-12T11:22:36.137Z"
   },
   {
    "duration": 2771,
    "start_time": "2025-03-12T11:26:08.552Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-12T11:27:12.038Z"
   },
   {
    "duration": 35,
    "start_time": "2025-03-12T11:27:40.972Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-12T11:28:32.833Z"
   },
   {
    "duration": 235,
    "start_time": "2025-03-12T11:29:24.711Z"
   },
   {
    "duration": 860,
    "start_time": "2025-03-12T11:36:05.288Z"
   },
   {
    "duration": 170,
    "start_time": "2025-03-12T11:37:17.260Z"
   },
   {
    "duration": 20,
    "start_time": "2025-03-12T11:37:37.137Z"
   },
   {
    "duration": 4,
    "start_time": "2025-03-12T11:37:51.446Z"
   },
   {
    "duration": 142,
    "start_time": "2025-03-12T11:37:56.963Z"
   },
   {
    "duration": 120,
    "start_time": "2025-03-12T11:38:39.523Z"
   },
   {
    "duration": 116,
    "start_time": "2025-03-12T11:38:47.881Z"
   },
   {
    "duration": 109,
    "start_time": "2025-03-12T11:38:51.082Z"
   },
   {
    "duration": 244,
    "start_time": "2025-03-12T12:13:48.109Z"
   },
   {
    "duration": 119,
    "start_time": "2025-03-12T12:15:34.017Z"
   },
   {
    "duration": 90,
    "start_time": "2025-03-12T12:16:00.125Z"
   },
   {
    "duration": 115,
    "start_time": "2025-03-12T12:18:30.638Z"
   },
   {
    "duration": 103,
    "start_time": "2025-03-12T12:19:23.711Z"
   },
   {
    "duration": 104,
    "start_time": "2025-03-12T12:24:51.764Z"
   },
   {
    "duration": 123,
    "start_time": "2025-03-12T12:24:57.685Z"
   },
   {
    "duration": 121,
    "start_time": "2025-03-12T12:25:24.794Z"
   },
   {
    "duration": 129,
    "start_time": "2025-03-12T12:25:57.967Z"
   },
   {
    "duration": 139,
    "start_time": "2025-03-12T12:26:08.110Z"
   },
   {
    "duration": 142,
    "start_time": "2025-03-12T12:26:43.040Z"
   },
   {
    "duration": 127,
    "start_time": "2025-03-12T12:27:29.064Z"
   },
   {
    "duration": 150,
    "start_time": "2025-03-12T12:27:48.309Z"
   },
   {
    "duration": 244,
    "start_time": "2025-03-12T12:28:33.423Z"
   },
   {
    "duration": 236,
    "start_time": "2025-03-12T12:29:21.243Z"
   },
   {
    "duration": 126,
    "start_time": "2025-03-12T12:29:29.838Z"
   },
   {
    "duration": 130,
    "start_time": "2025-03-12T12:29:36.604Z"
   },
   {
    "duration": 368,
    "start_time": "2025-03-12T12:29:49.555Z"
   },
   {
    "duration": 224,
    "start_time": "2025-03-12T12:31:07.720Z"
   },
   {
    "duration": 212,
    "start_time": "2025-03-12T12:31:13.214Z"
   },
   {
    "duration": 116,
    "start_time": "2025-03-12T12:31:58.523Z"
   },
   {
    "duration": 114,
    "start_time": "2025-03-12T12:32:52.523Z"
   },
   {
    "duration": 115,
    "start_time": "2025-03-12T12:33:43.605Z"
   },
   {
    "duration": 1223,
    "start_time": "2025-03-12T12:34:31.423Z"
   },
   {
    "duration": 117,
    "start_time": "2025-03-12T12:35:47.737Z"
   },
   {
    "duration": 1349,
    "start_time": "2025-03-12T12:36:36.395Z"
   },
   {
    "duration": 2848,
    "start_time": "2025-03-12T12:36:47.721Z"
   },
   {
    "duration": 2170,
    "start_time": "2025-03-12T12:36:50.570Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-12T12:36:52.741Z"
   },
   {
    "duration": 55,
    "start_time": "2025-03-12T12:36:52.761Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-12T12:36:52.818Z"
   },
   {
    "duration": 244,
    "start_time": "2025-03-12T12:36:52.855Z"
   },
   {
    "duration": 137,
    "start_time": "2025-03-12T12:36:53.101Z"
   },
   {
    "duration": 222,
    "start_time": "2025-03-12T12:36:53.240Z"
   },
   {
    "duration": 111,
    "start_time": "2025-03-12T12:37:28.289Z"
   },
   {
    "duration": 121,
    "start_time": "2025-03-12T12:37:38.987Z"
   },
   {
    "duration": 122,
    "start_time": "2025-03-12T12:48:22.484Z"
   },
   {
    "duration": 130,
    "start_time": "2025-03-12T12:48:32.349Z"
   },
   {
    "duration": 122,
    "start_time": "2025-03-12T12:48:41.561Z"
   },
   {
    "duration": 125,
    "start_time": "2025-03-12T12:48:54.580Z"
   },
   {
    "duration": 123,
    "start_time": "2025-03-12T12:49:11.769Z"
   },
   {
    "duration": 125,
    "start_time": "2025-03-12T12:49:28.898Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-12T13:15:41.358Z"
   },
   {
    "duration": 3,
    "start_time": "2025-03-12T13:16:10.168Z"
   },
   {
    "duration": 503,
    "start_time": "2025-03-12T13:16:41.211Z"
   },
   {
    "duration": 7,
    "start_time": "2025-03-12T13:16:59.907Z"
   },
   {
    "duration": 1537,
    "start_time": "2025-03-12T13:17:05.203Z"
   },
   {
    "duration": 1470,
    "start_time": "2025-03-12T13:17:36.005Z"
   },
   {
    "duration": 34,
    "start_time": "2025-03-12T13:18:47.847Z"
   },
   {
    "duration": 2295,
    "start_time": "2025-03-12T13:21:54.997Z"
   },
   {
    "duration": 708,
    "start_time": "2025-03-12T13:24:35.188Z"
   },
   {
    "duration": 476,
    "start_time": "2025-03-12T13:24:45.728Z"
   },
   {
    "duration": 461,
    "start_time": "2025-03-12T13:25:04.978Z"
   },
   {
    "duration": 42,
    "start_time": "2025-03-12T13:25:16.200Z"
   },
   {
    "duration": 18,
    "start_time": "2025-03-12T13:26:17.217Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-12T13:26:22.989Z"
   },
   {
    "duration": 25,
    "start_time": "2025-03-12T13:28:06.424Z"
   },
   {
    "duration": 24,
    "start_time": "2025-03-12T13:28:15.611Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-12T13:28:20.452Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-12T13:30:13.815Z"
   },
   {
    "duration": 474,
    "start_time": "2025-03-12T13:31:34.834Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-12T13:31:56.128Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-12T13:32:06.816Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-12T13:32:18.876Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-12T13:32:24.933Z"
   },
   {
    "duration": 15,
    "start_time": "2025-03-12T13:33:53.766Z"
   },
   {
    "duration": 503,
    "start_time": "2025-03-12T13:40:25.578Z"
   },
   {
    "duration": 13,
    "start_time": "2025-03-12T13:40:26.083Z"
   },
   {
    "duration": 4864,
    "start_time": "2025-03-12T13:40:40.801Z"
   },
   {
    "duration": 3611,
    "start_time": "2025-03-12T13:40:45.667Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-12T13:40:49.280Z"
   },
   {
    "duration": 36,
    "start_time": "2025-03-12T13:40:49.293Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-12T13:40:49.331Z"
   },
   {
    "duration": 242,
    "start_time": "2025-03-12T13:40:49.376Z"
   },
   {
    "duration": 149,
    "start_time": "2025-03-12T13:40:49.619Z"
   },
   {
    "duration": 500,
    "start_time": "2025-03-12T13:40:49.770Z"
   },
   {
    "duration": 337,
    "start_time": "2025-03-12T13:40:50.272Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-12T13:41:29.477Z"
   },
   {
    "duration": 21,
    "start_time": "2025-03-12T13:43:53.569Z"
   },
   {
    "duration": 231,
    "start_time": "2025-03-12T14:05:22.785Z"
   },
   {
    "duration": 4779,
    "start_time": "2025-03-12T14:08:32.908Z"
   },
   {
    "duration": 2491,
    "start_time": "2025-03-12T14:08:37.689Z"
   },
   {
    "duration": 14,
    "start_time": "2025-03-12T14:08:40.183Z"
   },
   {
    "duration": 54,
    "start_time": "2025-03-12T14:08:40.199Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-12T14:08:40.256Z"
   },
   {
    "duration": 248,
    "start_time": "2025-03-12T14:08:40.289Z"
   },
   {
    "duration": 148,
    "start_time": "2025-03-12T14:08:40.539Z"
   },
   {
    "duration": 504,
    "start_time": "2025-03-12T14:08:40.689Z"
   },
   {
    "duration": 344,
    "start_time": "2025-03-12T14:08:41.195Z"
   },
   {
    "duration": 0,
    "start_time": "2025-03-12T14:08:41.541Z"
   },
   {
    "duration": 58,
    "start_time": "2025-03-12T14:08:52.655Z"
   },
   {
    "duration": 78,
    "start_time": "2025-03-12T14:11:15.886Z"
   },
   {
    "duration": 30,
    "start_time": "2025-03-12T14:11:24.114Z"
   },
   {
    "duration": 8688,
    "start_time": "2025-03-12T14:16:10.715Z"
   },
   {
    "duration": 8519,
    "start_time": "2025-03-12T14:16:36.732Z"
   },
   {
    "duration": 5064,
    "start_time": "2025-03-12T14:16:54.265Z"
   },
   {
    "duration": 2356,
    "start_time": "2025-03-12T14:16:59.331Z"
   },
   {
    "duration": 12,
    "start_time": "2025-03-12T14:17:01.689Z"
   },
   {
    "duration": 56,
    "start_time": "2025-03-12T14:17:01.703Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-12T14:17:01.761Z"
   },
   {
    "duration": 263,
    "start_time": "2025-03-12T14:17:01.804Z"
   },
   {
    "duration": 153,
    "start_time": "2025-03-12T14:17:02.069Z"
   },
   {
    "duration": 506,
    "start_time": "2025-03-12T14:17:02.224Z"
   },
   {
    "duration": 8642,
    "start_time": "2025-03-12T14:17:02.732Z"
   },
   {
    "duration": 51,
    "start_time": "2025-03-12T14:17:11.375Z"
   },
   {
    "duration": 372,
    "start_time": "2025-03-12T14:17:11.428Z"
   },
   {
    "duration": 5024,
    "start_time": "2025-03-12T14:17:38.346Z"
   },
   {
    "duration": 2360,
    "start_time": "2025-03-12T14:17:43.372Z"
   },
   {
    "duration": 27,
    "start_time": "2025-03-12T14:17:45.737Z"
   },
   {
    "duration": 44,
    "start_time": "2025-03-12T14:17:45.766Z"
   },
   {
    "duration": 39,
    "start_time": "2025-03-12T14:17:45.812Z"
   },
   {
    "duration": 263,
    "start_time": "2025-03-12T14:17:45.853Z"
   },
   {
    "duration": 152,
    "start_time": "2025-03-12T14:17:46.118Z"
   },
   {
    "duration": 501,
    "start_time": "2025-03-12T14:17:46.272Z"
   },
   {
    "duration": 8656,
    "start_time": "2025-03-12T14:17:46.775Z"
   },
   {
    "duration": 67,
    "start_time": "2025-03-12T14:17:55.433Z"
   },
   {
    "duration": 386,
    "start_time": "2025-03-12T14:17:55.502Z"
   },
   {
    "duration": 55,
    "start_time": "2025-03-12T14:19:23.453Z"
   },
   {
    "duration": 53,
    "start_time": "2025-03-12T14:19:29.852Z"
   },
   {
    "duration": 5,
    "start_time": "2025-03-12T14:19:47.502Z"
   },
   {
    "duration": 5022,
    "start_time": "2025-03-12T14:42:12.305Z"
   },
   {
    "duration": 2210,
    "start_time": "2025-03-12T14:42:17.329Z"
   },
   {
    "duration": 22,
    "start_time": "2025-03-12T14:42:19.541Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-12T14:42:19.564Z"
   },
   {
    "duration": 31,
    "start_time": "2025-03-12T14:42:19.604Z"
   },
   {
    "duration": 253,
    "start_time": "2025-03-12T14:42:19.637Z"
   },
   {
    "duration": 150,
    "start_time": "2025-03-12T14:42:19.892Z"
   },
   {
    "duration": 520,
    "start_time": "2025-03-12T14:42:20.044Z"
   },
   {
    "duration": 8741,
    "start_time": "2025-03-12T14:42:20.566Z"
   },
   {
    "duration": 69,
    "start_time": "2025-03-12T14:42:29.309Z"
   },
   {
    "duration": 359,
    "start_time": "2025-03-12T14:42:29.380Z"
   },
   {
    "duration": 4912,
    "start_time": "2025-03-12T14:44:16.035Z"
   },
   {
    "duration": 2232,
    "start_time": "2025-03-12T14:44:20.949Z"
   },
   {
    "duration": 11,
    "start_time": "2025-03-12T14:44:23.183Z"
   },
   {
    "duration": 37,
    "start_time": "2025-03-12T14:44:23.196Z"
   },
   {
    "duration": 41,
    "start_time": "2025-03-12T14:44:23.235Z"
   },
   {
    "duration": 267,
    "start_time": "2025-03-12T14:44:23.278Z"
   },
   {
    "duration": 153,
    "start_time": "2025-03-12T14:44:23.547Z"
   },
   {
    "duration": 520,
    "start_time": "2025-03-12T14:44:23.702Z"
   },
   {
    "duration": 8552,
    "start_time": "2025-03-12T14:44:24.224Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "260.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
